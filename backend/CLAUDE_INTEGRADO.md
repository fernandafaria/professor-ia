# âœ… Claude API Integrado

## Status: MigraÃ§Ã£o Completa

A integraÃ§Ã£o com Claude API (Anthropic) foi concluÃ­da com sucesso!

## ğŸ”„ O que mudou

### Antes (OpenAI)
- SDK: `openai`
- Modelo: `gpt-4-turbo-preview`
- VariÃ¡vel: `OPENAI_API_KEY`

### Agora (Claude)
- SDK: `anthropic`
- Modelo: `claude-3-5-sonnet-20241022`
- VariÃ¡vel: `ANTHROPIC_API_KEY`

## ğŸ“‹ Arquivos Modificados

1. âœ… `app/services/llm_service.py` - Migrado para Claude API
2. âœ… `app/config.py` - ConfiguraÃ§Ãµes atualizadas
3. âœ… `requirements.txt` - Adicionado `anthropic==0.34.2`
4. âœ… `env.example` - InstruÃ§Ãµes atualizadas

## ğŸš€ Como Usar

### 1. Instalar dependÃªncia

```bash
cd /Users/fernandafaria/Downloads/P1A/backend
pip install anthropic==0.34.2
```

### 2. Obter API Key

1. Acesse: https://console.anthropic.com/
2. Crie uma conta ou faÃ§a login
3. VÃ¡ em **API Keys**
4. Crie uma nova chave
5. Copie (formato: `sk-ant-...`)

### 3. Configurar .env

```env
ANTHROPIC_API_KEY=sk-ant-sua-chave-aqui
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
```

### 4. Testar

```bash
uvicorn app.main:app --reload --port 8000
```

Acesse: http://localhost:8000/docs

## ğŸ¯ Modelos DisponÃ­veis

| Modelo | Uso | Custo |
|--------|-----|-------|
| `claude-3-5-sonnet-20241022` | **Recomendado** - Melhor custo-benefÃ­cio | MÃ©dio |
| `claude-3-opus-20240229` | Melhor qualidade | Alto |
| `claude-3-haiku-20240307` | Mais rÃ¡pido e barato | Baixo |

## âœ¨ Vantagens do Claude

1. **Melhor em PortuguÃªs** - Treinado com mais dados em portuguÃªs brasileiro
2. **Contexto Maior** - AtÃ© 200k tokens de contexto
3. **Mais Seguro** - Menos alucinaÃ§Ãµes e respostas mais precisas
4. **Ideal para EducaÃ§Ã£o** - Respostas mais didÃ¡ticas e explicativas
5. **Custo-BenefÃ­cio** - Claude 3.5 Sonnet Ã© competitivo

## ğŸ”§ Funcionalidades Mantidas

- âœ… Chat com streaming
- âœ… Sistema RAG integrado
- âœ… PersonalizaÃ§Ã£o por perfil
- âœ… HistÃ³rico de conversas
- âœ… Metadata de tokens e latÃªncia

## ğŸ“ Notas TÃ©cnicas

### DiferenÃ§as na API

**OpenAI:**
```python
messages = [{"role": "system", ...}, {"role": "user", ...}]
response = await client.chat.completions.create(...)
```

**Claude:**
```python
system = "..."  # Separado
messages = [{"role": "user", ...}]
response = await client.messages.create(
    system=system,
    messages=messages,
    ...
)
```

### Streaming

O streaming funciona de forma similar, mas usa `async with` e `stream.text_stream`:

```python
async with client.messages.stream(...) as stream:
    async for text in stream.text_stream:
        yield text
```

## âš ï¸ Importante

- **Embeddings**: Ainda pode usar OpenAI para embeddings (opcional) ou sentence-transformers (local)
- **Compatibilidade**: Todos os endpoints permanecem iguais
- **RAG**: Sistema RAG continua funcionando normalmente

---

**IntegraÃ§Ã£o concluÃ­da!** ğŸ‰

Para mais detalhes, veja: `MIGRACAO_CLAUDE.md`
