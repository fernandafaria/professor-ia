"""
Servi√ßo de integra√ß√£o com LLM (Anthropic Claude).
Conforme especifica√ß√£o MVP - Se√ß√£o 5.2 e 5.3
"""

from sqlalchemy.orm import Session
from typing import List, Dict, AsyncGenerator
from anthropic import AsyncAnthropic
from app.config import settings
from app.models.conversation import Conversation
from app.models.message import Message
from app.models.professor_profile import ProfessorProfile
from app.core.rag.retriever_supabase import RAGRetriever
from app.core.rag.prompts import PromptTemplates
import time

class LLMService:
    """Servi√ßo de integra√ß√£o com LLM (Claude)."""
    
    def __init__(self, db: Session):
        """Inicializa o servi√ßo LLM."""
        self.db = db
        self.client = AsyncAnthropic(api_key=settings.ANTHROPIC_API_KEY)
        self.rag_retriever = RAGRetriever(db=db)
    
    async def generate_response(
        self,
        conversation: Conversation,
        user_message: str,
        previous_messages: List[Message]
    ) -> Dict:
        """Gera resposta da IA para uma mensagem."""
        start_time = time.time()
        
        # Obter perfil do professor
        profile = self.db.query(ProfessorProfile).filter(
            ProfessorProfile.id == conversation.profile_id
        ).first()
        
        if not profile:
            raise ValueError("Profile not found")
        
        # Construir hist√≥rico de conversa
        conversation_history = []
        for msg in previous_messages[-10:]:  # √öltimas 10 mensagens
            conversation_history.append({
                "role": msg.role.value,
                "content": msg.content
            })
        
        # Buscar contexto RAG
        rag_context = []
        rag_results = []
        try:
            rag_results = self.rag_retriever.retrieve(user_message, db=self.db, n_results=5)
            rag_context = [r.get("content", "") for r in rag_results]
        except Exception as e:
            print(f"Erro ao buscar contexto RAG: {e}")
        
        # Construir prompt do sistema
        system_prompt = self._build_system_prompt(profile, rag_context)
        
        # Construir mensagens para o Claude
        # Claude usa formato diferente: system √© separado e messages s√£o apenas user/assistant
        messages = []
        
        # Adicionar hist√≥rico (converter formato)
        for msg in conversation_history:
            # Claude n√£o aceita "system" nas messages, apenas user/assistant
            if msg["role"] == "system":
                continue
            messages.append({
                "role": msg["role"],  # user ou assistant
                "content": msg["content"]
            })
        
        # Adicionar mensagem atual
        messages.append({"role": "user", "content": user_message})
        
        # Chamar Claude API
        try:
            response = await self.client.messages.create(
                model=settings.ANTHROPIC_MODEL,
                max_tokens=1024,
                temperature=0.7,
                system=system_prompt,
                messages=messages,
            )
            
            # Claude retorna texto diretamente no primeiro content block
            content = response.content[0].text if response.content else ""
            
            # Obter informa√ß√µes de uso
            tokens_used = response.usage.input_tokens + response.usage.output_tokens if hasattr(response, 'usage') else 0
            latency = int((time.time() - start_time) * 1000)  # em ms
            
            return {
                "content": content,
                "metadata": {
                    "tokens": tokens_used,
                    "input_tokens": response.usage.input_tokens if hasattr(response, 'usage') else 0,
                    "output_tokens": response.usage.output_tokens if hasattr(response, 'usage') else 0,
                    "model": settings.ANTHROPIC_MODEL,
                    "latency": latency,
                    "rag_sources": [r.get("metadata", {}).get("source", "") for r in rag_results] if rag_context else []
                }
            }
        except Exception as e:
            raise Exception(f"Erro ao gerar resposta: {str(e)}")
    
    async def generate_response_stream(
        self,
        conversation: Conversation,
        user_message: str,
        previous_messages: List[Message]
    ) -> AsyncGenerator[str, None]:
        """Gera resposta da IA com streaming."""
        # Obter perfil do professor
        profile = self.db.query(ProfessorProfile).filter(
            ProfessorProfile.id == conversation.profile_id
        ).first()
        
        if not profile:
            raise ValueError("Profile not found")
        
        # Construir hist√≥rico de conversa
        conversation_history = []
        for msg in previous_messages[-10:]:
            conversation_history.append({
                "role": msg.role.value,
                "content": msg.content
            })
        
        # Buscar contexto RAG
        rag_context = []
        rag_results = []
        try:
            rag_results = self.rag_retriever.retrieve(user_message, db=self.db, n_results=5)
            rag_context = [r.get("content", "") for r in rag_results]
        except Exception as e:
            print(f"Erro ao buscar contexto RAG: {e}")
        
        # Construir prompt do sistema
        system_prompt = self._build_system_prompt(profile, rag_context)
        
        # Construir mensagens para o Claude
        messages = []
        
        # Adicionar hist√≥rico (converter formato)
        for msg in conversation_history:
            if msg["role"] == "system":
                continue
            messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })
        
        messages.append({"role": "user", "content": user_message})
        
        # Chamar Claude API com streaming
        try:
            async with self.client.messages.stream(
                model=settings.ANTHROPIC_MODEL,
                max_tokens=1024,
                temperature=0.7,
                system=system_prompt,
                messages=messages,
            ) as stream:
                async for text in stream.text_stream:
                    yield text
        except Exception as e:
            raise Exception(f"Erro ao gerar resposta com streaming: {str(e)}")
    
    def _build_system_prompt(
        self,
        profile: ProfessorProfile,
        rag_context: List[str]
    ) -> str:
        """Constr√≥i prompt do sistema conforme especifica√ß√£o MVP - Se√ß√£o 5.3."""
        # Diretrizes por personalidade
        personality_guidelines = {
            "motivador": """
- Use linguagem encorajadora e positiva
- Celebre pequenas conquistas
- Proponha desafios progressivos
- Use emojis de celebra√ß√£o (üéâ, üöÄ, ‚≠ê)
- Frases: "Voc√™ consegue!", "√ìtimo racioc√≠nio!", "Vamos nessa!"
""",
            "paciente": """
- Explique de m√∫ltiplas formas
- N√£o demonstre pressa ou frustra√ß√£o
- Ofere√ßa pausas e revis√µes
- Use analogias simples
- Frases: "Vamos com calma", "N√£o tem problema errar", "Quer que eu explique de outra forma?"
""",
            "desafiador": """
- Proponha exerc√≠cios dif√≠ceis
- Questione respostas superficiais
- Estimule pensamento cr√≠tico
- Use tom direto
- Frases: "Voc√™ pode ir al√©m", "Pense mais profundamente", "Esse racioc√≠nio est√° incompleto"
""",
            "amigavel": """
- Use g√≠rias e linguagem informal
- Insira refer√™ncias pop
- Use emojis frequentemente (üòé, ü§ô, üî•)
- Crie conex√£o emocional
- Frases: "Opa, beleza?", "Bora l√°!", "Massa demais!"
""",
        }
        
        # Construir contexto RAG
        context_text = "\n\n".join([f"- {c}" for c in rag_context]) if rag_context else "Nenhum contexto espec√≠fico dispon√≠vel."
        
        # Construir prompt completo
        prompt = f"""Voc√™ √© {profile.professor_name}, um professor de {profile.subject.value} com personalidade {profile.personality.value}.

PERFIL DO ALUNO:
- N√≠vel: {profile.level.value}
- Interesses: {', '.join(profile.interests) if profile.interests else 'Nenhum especificado'}
- Objetivo: {profile.goal or 'N√£o especificado'}
- Mat√©rias favoritas: {', '.join(profile.favorite_subjects) if profile.favorite_subjects else 'Nenhuma especificada'}

DIRETRIZES DE COMUNICA√á√ÉO:
{personality_guidelines.get(profile.personality.value, '')}

CONTEXTO PEDAG√ìGICO (BNCC):
{context_text}

HIST√ìRICO DA CONVERSA:
[Ser√° preenchido com as mensagens anteriores]

INSTRU√á√ÉO:
Responda de forma clara, adaptando exemplos aos interesses do aluno. Use exemplos relacionados a {', '.join(profile.interests[:2]) if profile.interests else 'interesses gerais'} quando apropriado.
"""
        return prompt
