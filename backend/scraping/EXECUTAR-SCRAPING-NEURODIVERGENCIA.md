# ğŸš€ Executar Scraping de Papers sobre NeurodivergÃªncias

## ğŸ“‹ Script Criado

**Arquivo:** `scrape_neurodivergence_papers.py`

Este script executa o scraping completo de papers acadÃªmicos sobre neurodivergÃªncias e organiza os dados para RAG.

---

## ğŸ¯ Funcionalidades

1. **Busca em mÃºltiplas fontes:**
   - PubMed (API pÃºblica)
   - SciELO Brasil (API pÃºblica)
   - ERIC (se API key configurada)

2. **Processamento:**
   - ValidaÃ§Ã£o de qualidade
   - Chunking para RAG
   - Enriquecimento de metadados

3. **OrganizaÃ§Ã£o para RAG:**
   - Adiciona ao ChromaDB
   - Metadados estruturados
   - IndexaÃ§Ã£o semÃ¢ntica

---

## ğŸš€ Uso RÃ¡pido

### ExecuÃ§Ã£o BÃ¡sica

```bash
cd backend
python scraping/scrape_neurodivergence_papers.py
```

**O que faz:**
- Busca papers sobre TDAH, dislexia e autismo
- Processa e organiza para RAG
- Adiciona ao ChromaDB automaticamente
- Salva papers em JSON

### OpÃ§Ãµes DisponÃ­veis

```bash
# Buscar apenas TDAH
python scraping/scrape_neurodivergence_papers.py --types ADHD

# Buscar todos os tipos
python scraping/scrape_neurodivergence_papers.py --types ADHD dyslexia autism neurodivergence

# Limitar resultados (mais rÃ¡pido)
python scraping/scrape_neurodivergence_papers.py --max-results 10

# Apenas coletar, nÃ£o adicionar ao RAG
python scraping/scrape_neurodivergence_papers.py --no-rag

# NÃ£o salvar JSON
python scraping/scrape_neurodivergence_papers.py --no-save

# Ajustar tamanho dos chunks
python scraping/scrape_neurodivergence_papers.py --chunk-size 1500
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente (Opcional)

```bash
# ERIC API Key (opcional, mas recomendado)
export ERIC_API_KEY="sua_chave_aqui"

# ChromaDB (se nÃ£o usar padrÃ£o)
export CHROMA_HOST="localhost"
export CHROMA_PORT=8000
```

### Obter ERIC API Key

1. Acesse: https://api.ies.ed.gov/
2. Registre-se para obter chave gratuita
3. Configure: `export ERIC_API_KEY="sua_chave"`

---

## ğŸ“Š O Que SerÃ¡ Coletado

### Tipos de NeurodivergÃªncia

- **ADHD/TDAH** - Transtorno de DÃ©ficit de AtenÃ§Ã£o e Hiperatividade
- **Dyslexia/Dislexia** - Dificuldades de leitura
- **Autism/TEA** - Transtorno do Espectro Autista
- **Neurodivergence** - Geral sobre neurodiversidade

### Por Tipo, Busca:

- **PubMed:** Papers em inglÃªs sobre intervenÃ§Ãµes educacionais
- **SciELO:** Papers em portuguÃªs sobre educaÃ§Ã£o inclusiva
- **ERIC:** Papers educacionais (se API key configurada)

---

## ğŸ“ Estrutura de Dados

### Papers Coletados (JSON)

Salvos em: `backend/data/raw/papers_{tipo}_{data}.json`

```json
{
  "title": "IntervenÃ§Ãµes Educacionais para TDAH",
  "abstract": "Resumo do paper...",
  "authors": ["Autor 1", "Autor 2"],
  "publication_date": "2024-01-15",
  "doi": "10.1234/example",
  "source_url": "https://pubmed.ncbi.nlm.nih.gov/12345",
  "keywords": ["TDAH", "educaÃ§Ã£o", "intervenÃ§Ã£o"],
  "source_database": "PubMed",
  "language": "en"
}
```

### Chunks para RAG

Cada paper Ã© dividido em chunks com:
- **ConteÃºdo:** TÃ­tulo + Abstract + Autores + Keywords
- **Metadados:**
  - Tipo de neurodivergÃªncia
  - Fonte (PubMed, SciELO, ERIC)
  - Autores, DOI, data
  - Keywords
  - Idioma

---

## ğŸ”„ Pipeline Completo

```
1. Busca Papers
   â”œâ”€â”€ PubMed (API)
   â”œâ”€â”€ SciELO (API)
   â””â”€â”€ ERIC (API/Web)
   
2. ValidaÃ§Ã£o
   â”œâ”€â”€ TÃ­tulo mÃ­nimo
   â”œâ”€â”€ Abstract mÃ­nimo
   â””â”€â”€ RemoÃ§Ã£o de duplicatas
   
3. Processamento
   â”œâ”€â”€ CriaÃ§Ã£o de conteÃºdo combinado
   â”œâ”€â”€ Chunking (2000 chars, 400 overlap)
   â””â”€â”€ Enriquecimento de metadados
   
4. OrganizaÃ§Ã£o RAG
   â”œâ”€â”€ GeraÃ§Ã£o de embeddings
   â”œâ”€â”€ AdiÃ§Ã£o ao ChromaDB
   â””â”€â”€ IndexaÃ§Ã£o semÃ¢ntica
```

---

## ğŸ“ˆ EstatÃ­sticas Esperadas

### Por Tipo de NeurodivergÃªncia:

- **ADHD:** ~30-50 papers (PubMed + SciELO)
- **Dyslexia:** ~30-50 papers
- **Autism:** ~30-50 papers
- **Neurodivergence:** ~20-30 papers

**Total estimado:** ~100-200 papers Ãºnicos
**Total de chunks:** ~300-600 chunks (dependendo do tamanho dos abstracts)

---

## âœ… Verificar Resultados

### Verificar Papers Coletados

```bash
# Listar arquivos JSON
ls -lh backend/data/raw/papers_*.json

# Ver conteÃºdo de um arquivo
cat backend/data/raw/papers_ADHD_*.json | head -50
```

### Verificar RAG

```python
from backend.app.core.rag.retriever import RAGRetriever

retriever = RAGRetriever()

# Buscar papers sobre TDAH
results = retriever.retrieve(
    query="estratÃ©gias educacionais para TDAH",
    n_results=5,
    filters={"neurodivergence_type": "ADHD"}
)

for doc in results:
    print(f"TÃ­tulo: {doc['metadata'].get('title')}")
    print(f"Fonte: {doc['metadata'].get('source')}")
    print(f"ConteÃºdo: {doc['content'][:200]}...")
    print("---")
```

---

## âš ï¸ ConsideraÃ§Ãµes

1. **Rate Limiting:**
   - PubMed: 3 requisiÃ§Ãµes/segundo
   - SciELO: Respeitar delays
   - ERIC: Depende da API key

2. **Tempo de ExecuÃ§Ã£o:**
   - ~5-10 minutos para buscar todos os tipos
   - Depende da quantidade de resultados

3. **Qualidade dos Dados:**
   - Apenas papers com abstract mÃ­nimo sÃ£o processados
   - Duplicatas sÃ£o removidas automaticamente

4. **Armazenamento:**
   - Papers salvos em JSON (~1-5 MB por tipo)
   - Chunks no ChromaDB (depende do tamanho)

---

## ğŸ”§ Troubleshooting

### Erro: "Connection refused"
- Verifique se ChromaDB estÃ¡ rodando
- Configure `CHROMA_HOST` e `CHROMA_PORT`

### Erro: "No papers found"
- Verifique conexÃ£o com internet
- Tente reduzir `--max-results`
- Verifique se termos de busca estÃ£o corretos

### Erro: "API rate limit exceeded"
- Aguarde alguns minutos
- Reduza `--max-results`
- Use `--no-rag` para apenas coletar

---

## ğŸ“š PrÃ³ximos Passos

ApÃ³s executar o scraping:

1. **Verificar qualidade dos dados:**
   ```bash
   python scraping/scrape_neurodivergence_papers.py --no-rag --no-save
   ```

2. **Testar recuperaÃ§Ã£o:**
   ```python
   # Usar o cÃ³digo de verificaÃ§Ã£o acima
   ```

3. **Integrar com sistema de chat:**
   - Os papers jÃ¡ estarÃ£o disponÃ­veis no RAG
   - O sistema pode usar para contextualizar respostas

---

**Ãšltima AtualizaÃ§Ã£o:** 2025-01-08
