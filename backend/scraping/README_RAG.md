# üìö Guia R√°pido: Popular RAG com Conte√∫do Educacional

## üöÄ Comando Mais R√°pido

```bash
# Verificar se tudo est√° OK
python -m backend.scraping.check_setup

# Popular RAG (MVP completo)
python -m backend.scraping.populate_rag --phase mvp
```

**Pronto!** Isso vai coletar conte√∫do das 3 fontes priorit√°rias e adicionar ao RAG.

---

## üìã O Que Acontece

1. **API BNCC Cientificar** ‚Üí Estrutura curricular completa
2. **Projeto √Ågatha Edu** ‚Üí Quest√µes ENEM/vestibulares (50 p√°ginas)
3. **Nova Escola** ‚Üí Planos de aula (100 p√°ginas)

Tudo √© processado, dividido em chunks e adicionado ao ChromaDB (RAG).

---

## ‚öôÔ∏è Pr√©-requisitos

### 1. Vari√°veis de Ambiente

```bash
export FIRECRAWL_API_KEY='fc-d9e38b1898aa4067be99276054db16be'
export DATABASE_URL='postgresql://user:pass@localhost/dbname'  # Se usar PostgreSQL
export SECRET_KEY='sua-secret-key-aqui'
```

### 2. ChromaDB Rodando

```bash
# Instalar ChromaDB
pip install chromadb

# Iniciar servidor
chroma run --host localhost --port 8000
```

### 3. Depend√™ncias

```bash
pip install -r backend/requirements.txt
```

---

## üéØ Op√ß√µes de Execu√ß√£o

### Op√ß√£o 1: MVP Completo (Recomendado para come√ßar)

```bash
python -m backend.scraping.populate_rag --phase mvp
```

### Op√ß√£o 2: Apenas Conte√∫do Cultural

```bash
python -m backend.scraping.populate_rag --phase cultural
```

### Op√ß√£o 3: Tudo (MVP + Cultural)

```bash
python -m backend.scraping.populate_rag --phase all
```

### Op√ß√£o 4: Verificar Status do RAG

```bash
python -m backend.scraping.populate_rag --phase verify
```

### Op√ß√£o 5: Testar Recupera√ß√£o

```bash
python -m backend.scraping.populate_rag --phase test --test-query "equa√ß√µes de segundo grau"
```

---

## üìä Monitoramento

O script mostra progresso em tempo real:

```
[1/3] Coletando dados da API BNCC Cientificar...
‚úì BNCC: 150 chunks coletados

[2/3] Coletando quest√µes do Projeto √Ågatha Edu...
‚úì Projeto √Ågatha: 320 chunks coletados

[3/3] Coletando planos de aula da Nova Escola...
‚úì Nova Escola: 450 chunks coletados

üìö Adicionando 920 chunks ao RAG...
‚úì Documentos adicionados ao RAG com sucesso!
```

---

## üîß Troubleshooting

### ChromaDB n√£o conecta

```bash
# Verificar se est√° rodando
curl http://localhost:8000/api/v1/heartbeat

# Iniciar se n√£o estiver
chroma run --host localhost --port 8000
```

### Firecrawl n√£o funciona

```bash
# Verificar API key
echo $FIRECRAWL_API_KEY

# Usar scrapers tradicionais
python -m backend.scraping.populate_rag --phase mvp --no-firecrawl
```

### Poucos documentos coletados

- Aumentar `max_pages` gradualmente
- Verificar logs para erros espec√≠ficos
- Testar scraping manual de uma URL

---

## üìà Pr√≥ximos Passos Ap√≥s Popular

1. **Testar Queries**
   ```python
   from backend.app.core.rag.retriever import RAGRetriever
   
   retriever = RAGRetriever()
   results = retriever.retrieve("matem√°tica b√°sica", n_results=5)
   ```

2. **Integrar com API**
   - Usar RAGRetriever na API
   - Criar endpoints para queries
   - Testar com frontend

3. **Otimizar**
   - Ajustar chunk_size
   - Melhorar metadados
   - Adicionar filtros

---

## üìö Documenta√ß√£o Completa

- [Pr√≥ximos Passos Detalhados](./PROXIMOS_PASSOS_RAG.md)
- [Guia do Firecrawl](./FIRECRAWL_GUIDE.md)
- [README do Scraping](./README.md)

---

**Tempo estimado para MVP:** 30-60 minutos
