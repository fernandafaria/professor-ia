# üöÄ Pr√≥ximos Passos para Criar Conte√∫do para RAG

Guia passo a passo para popular a base de conhecimento RAG com conte√∫do educacional.

## üìã Checklist de Prepara√ß√£o

### 1. Verificar Configura√ß√µes

```bash
# Verificar se ChromaDB est√° rodando
# ChromaDB deve estar em localhost:8000 (padr√£o)

# Verificar vari√°veis de ambiente
export FIRECRAWL_API_KEY='fc-d9e38b1898aa4067be99276054db16be'
export DATABASE_URL='postgresql://user:pass@localhost/dbname'
export SECRET_KEY='sua-secret-key-aqui'
```

### 2. Instalar Depend√™ncias

```bash
cd backend
pip install -r requirements.txt
```

### 3. Verificar Infraestrutura

- ‚úÖ ChromaDB rodando (porta 8000)
- ‚úÖ PostgreSQL configurado (se necess√°rio)
- ‚úÖ Redis rodando (para Celery, se usar)

---

## üéØ Passo 1: Popular RAG com Conte√∫do MVP

### Op√ß√£o A: Script Automatizado (Recomendado)

```bash
# Popular com fontes priorit√°rias (MVP)
python -m backend.scraping.populate_rag --phase mvp

# Com Firecrawl (recomendado)
python -m backend.scraping.populate_rag --phase mvp

# Sem Firecrawl (scrapers tradicionais)
python -m backend.scraping.populate_rag --phase mvp --no-firecrawl
```

### Op√ß√£o B: Via CLI Individual

```bash
# 1. Coletar dados BNCC
python -m backend.scraping.cli --source "API BNCC Cientificar"

# 2. Coletar quest√µes do Projeto √Ågatha (com Firecrawl)
python -m backend.scraping.cli \
    --source "Projeto √Ågatha Edu" \
    --use-firecrawl \
    --crawl \
    --max-pages 50

# 3. Coletar planos de aula da Nova Escola (com Firecrawl)
python -m backend.scraping.cli \
    --source "Nova Escola" \
    --use-firecrawl \
    --crawl \
    --max-pages 100
```

### Op√ß√£o C: Via Python (Program√°tico)

```python
from backend.scraping.populate_rag import RAGPopulator

populator = RAGPopulator()

# Popular MVP
stats = populator.populate_phase1_mvp(use_firecrawl=True)

print(f"Total de chunks: {stats['total_chunks']}")
print(f"Adicionado ao RAG: {stats['added_to_rag']}")
```

---

## üìä Passo 2: Verificar Conte√∫do Coletado

```bash
# Verificar quantos documentos est√£o no RAG
python -m backend.scraping.populate_rag --phase verify

# Testar recupera√ß√£o
python -m backend.scraping.populate_rag --phase test --test-query "matem√°tica b√°sica"
```

---

## üé® Passo 3: Adicionar Conte√∫do Cultural (Opcional)

Para personaliza√ß√£o com interesses dos alunos:

```bash
# Popular conte√∫do cultural (games, futebol, m√∫sica)
python -m backend.scraping.populate_rag --phase cultural --max-pages 20
```

---

## üîÑ Passo 4: Pipeline Completo

```bash
# Executar todas as fases
python -m backend.scraping.populate_rag --phase all
```

---

## üìà Sequ√™ncia Recomendada (Fase por Fase)

### Fase 1: MVP (Prioridade Cr√≠tica)

**Objetivo:** Ter conte√∫do b√°sico funcionando

```bash
# 1. Come√ßar com API BNCC (mais r√°pido, n√£o precisa scraping)
python -m backend.scraping.cli --source "API BNCC Cientificar"

# 2. Adicionar quest√µes (Projeto √Ågatha)
python -m backend.scraping.cli \
    --source "Projeto √Ågatha Edu" \
    --use-firecrawl \
    --crawl \
    --max-pages 20  # Come√ßar pequeno para testar

# 3. Adicionar planos de aula (Nova Escola)
python -m backend.scraping.cli \
    --source "Nova Escola" \
    --use-firecrawl \
    --crawl \
    --max-pages 30  # Come√ßar pequeno
```

**Meta:** 500-1000 chunks no RAG

### Fase 2: Expans√£o

**Objetivo:** Aumentar volume e qualidade

```bash
# Aumentar volume das fontes principais
python -m backend.scraping.cli \
    --source "Projeto √Ågatha Edu" \
    --use-firecrawl \
    --crawl \
    --max-pages 100

python -m backend.scraping.cli \
    --source "Nova Escola" \
    --use-firecrawl \
    --crawl \
    --max-pages 200
```

**Meta:** 5000-10000 chunks no RAG

### Fase 3: Personaliza√ß√£o

**Objetivo:** Adicionar conte√∫do cultural

```bash
# Conte√∫do cultural
python -m backend.scraping.populate_rag --phase cultural
```

**Meta:** 10000+ chunks com diversidade de conte√∫do

---

## üß™ Testar o RAG

### Teste B√°sico

```python
from backend.app.core.rag.retriever import RAGRetriever

retriever = RAGRetriever()

# Testar recupera√ß√£o
results = retriever.retrieve("equa√ß√µes de segundo grau", n_results=5)

for doc in results:
    print(f"T√≠tulo: {doc['metadata'].get('title', 'N/A')}")
    print(f"Conte√∫do: {doc['content'][:200]}...")
    print("-" * 60)
```

### Teste com Personaliza√ß√£o

```python
# Testar com interesses do aluno
results = retriever.retrieve(
    "explicar fun√ß√µes matem√°ticas",
    n_results=5,
    student_interests=["Fortnite", "futebol"]
)
```

---

## üìù Monitoramento e Manuten√ß√£o

### Verificar Status do RAG

```bash
# Verificar quantos documentos
python -m backend.scraping.populate_rag --phase verify
```

### Atualizar Conte√∫do

```bash
# Re-executar para atualizar
python -m backend.scraping.populate_rag --phase mvp
```

### Logs

Os logs mostram:
- Quantos documentos foram coletados por fonte
- Quantos chunks foram criados
- Se foram adicionados ao RAG com sucesso
- Erros (se houver)

---

## ‚ö†Ô∏è Troubleshooting

### Problema: ChromaDB n√£o conecta

```bash
# Verificar se ChromaDB est√° rodando
# Instalar e iniciar ChromaDB:
pip install chromadb
chroma run --host localhost --port 8000
```

### Problema: Firecrawl n√£o funciona

```bash
# Verificar API key
echo $FIRECRAWL_API_KEY

# Usar scrapers tradicionais
python -m backend.scraping.populate_rag --phase mvp --no-firecrawl
```

### Problema: Poucos documentos coletados

- Verificar se as URLs est√£o corretas no `sources.yaml`
- Testar scraping manual de uma URL
- Verificar logs para erros espec√≠ficos
- Aumentar `max_pages` gradualmente

---

## üéØ Metas por Fase

| Fase | Chunks M√≠nimos | Chunks Ideais | Fontes |
|------|----------------|---------------|--------|
| MVP | 500 | 1.000 | BNCC, √Ågatha, Nova Escola |
| Expans√£o | 5.000 | 10.000 | + Olimp√≠adas, QConcursos |
| Personaliza√ß√£o | 10.000 | 20.000+ | + Conte√∫do cultural |

---

## üìö Pr√≥ximos Passos Ap√≥s Popular RAG

1. **Testar Queries Reais**
   - Criar queries de alunos reais
   - Verificar qualidade das respostas
   - Ajustar prompts se necess√°rio

2. **Otimizar Embeddings**
   - Testar diferentes modelos
   - Ajustar chunk_size e overlap
   - Melhorar metadados

3. **Adicionar Filtros**
   - Filtrar por s√©rie/ano
   - Filtrar por disciplina
   - Filtrar por tipo de conte√∫do

4. **Monitorar Performance**
   - Tempo de recupera√ß√£o
   - Relev√¢ncia dos resultados
   - Uso de recursos

---

## üöÄ Comando R√°pido para Come√ßar

```bash
# Tudo em um comando (MVP completo)
python -m backend.scraping.populate_rag --phase mvp
```

Este comando vai:
1. ‚úÖ Coletar dados da API BNCC
2. ‚úÖ Coletar quest√µes do Projeto √Ågatha (50 p√°ginas)
3. ‚úÖ Coletar planos de aula da Nova Escola (100 p√°ginas)
4. ‚úÖ Processar e fazer chunking
5. ‚úÖ Adicionar tudo ao RAG
6. ‚úÖ Mostrar estat√≠sticas finais

**Tempo estimado:** 30-60 minutos (dependendo do volume)

---

**√öltima atualiza√ß√£o:** 2026-01-08
